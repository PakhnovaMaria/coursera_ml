{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2) (2000, 2) (500, 2)\n"
     ]
    }
   ],
   "source": [
    "# Считываем данные\n",
    "test = pd.read_csv('products_sentiment_test.tsv', sep='\\t')\n",
    "train = pd.read_csv('products_sentiment_train.tsv', sep='\\t',  header=None)\n",
    "classes = pd.read_csv('products_sentiment_sample_submission.csv')\n",
    "print(test.shape, train.shape, classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>so , why the small digital elph , rather than ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3/4 way through the first disk we played on it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>better for the zen micro is outlook compatibil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6 . play gameboy color games on it with goboy .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>likewise , i 've heard norton 2004 professiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>495</td>\n",
       "      <td>i took perfect care of this player and still i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>it 's a very intuitive program .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>497</td>\n",
       "      <td>the only drawback is the viewfinder is slightl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>it films 10 second video , for crying out loud .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>499</td>\n",
       "      <td>everything shines of quality .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id                                               text\n",
       "0      0  so , why the small digital elph , rather than ...\n",
       "1      1  3/4 way through the first disk we played on it...\n",
       "2      2  better for the zen micro is outlook compatibil...\n",
       "3      3    6 . play gameboy color games on it with goboy .\n",
       "4      4  likewise , i 've heard norton 2004 professiona...\n",
       "..   ...                                                ...\n",
       "495  495  i took perfect care of this player and still i...\n",
       "496  496                  it 's a very intuitive program . \n",
       "497  497  the only drawback is the viewfinder is slightl...\n",
       "498  498   it films 10 second video , for crying out loud .\n",
       "499  499                     everything shines of quality .\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Смотрим распределение целевой переменной\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "y.value_counts(normalize=True).plot(kind='bar');\n",
    "plt.title(\"Распределение целевой переменной\");\n",
    "plt.xlabel(\"Отзыв\");\n",
    "plt.ylabel(\"Количество текстов\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test =  mine was 2 weeks old and i chucked it in the trash , where it belongs . \n",
      "train =  you can manage your profile , change the contrast of backlight , make different type of display , either list or tabbed . \n"
     ]
    }
   ],
   "source": [
    "# Делаем из датафрейма сериес\n",
    "test = test['text']\n",
    "train = train[0]\n",
    "print('test = ', test.iloc[5])\n",
    "print('train = ', train.iloc[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим количество фич\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(train)\n",
    "print(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lesika\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = stop,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "\n",
    "#train_data_features = vectorizer.fit_transform(train)\n",
    "\n",
    "#train_data_features = train_data_features.toarray()\n",
    "#train_data_features.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим пайплан и модель на линейной регрессии\n",
    "pipe = Pipeline([\n",
    "    ('сv', vectorizer),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))])\n",
    "accuracy = cross_val_score(pipe, train, y, cv=5, scoring='accuracy' )\n",
    "print('accuracy на линейной регрессии, при наличии стоп слов и без токинезации равно {}'.format(accuracy.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пробуем разные модели с разными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('сv', vectorizer),\n",
    "    ('forest', RandomForestClassifier(n_estimators = 100))])\n",
    "accuracy = cross_val_score(pipe, train, y, cv=5, scoring='accuracy' )\n",
    "print('accuracy на случайном лесе (100 эстиматоров), при наличии стоп слов и без токинезации равно {}'.format(accuracy.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('сv', vectorizer),\n",
    "    ('forest', RandomForestClassifier(n_estimators = 500))])\n",
    "accuracy = cross_val_score(pipe, train, y, cv=5, scoring='accuracy' )\n",
    "print('accuracy на случайном лесе (500 эстиматоров), при наличии стоп слов и без токинезации равно {}'.format(accuracy.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_vectorizer = {\n",
    "    'vectorizer__max_df' : [0.85, 0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df' : [1, 10, 20], \n",
    "    'vectorizer__ngram_range' : [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)],\n",
    "    'vectorizer__stop_words' : [stop, None, 'english']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vectorizer,  dense,pca, classifier):\n",
    "    return Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            #('transformer', transformer),\n",
    "            ('dense',dense),\n",
    "            ('pca', pca),\n",
    "            ('classifier', classifier)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(classifier, params_grid, scorer, data, labels):\n",
    "    pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), classifier)\n",
    "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring=scorer, cv=5, random_state=777, n_iter=100)\n",
    "    grid_cv.fit(data, labels)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for name, clf in {'LogisticRegression': LogisticRegression, 'LinearSVC': LinearSVC, \n",
    "               'SGDClassifier': SGDClassifier, 'RidgeClassifier': RidgeClassifier}.items():\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=777)), train, y, cv=5).mean()\n",
    "    print(f\"{name} - {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models={}\n",
    "for name, clf in {'LogisticRegression': LogisticRegression, 'LinearSVC': LinearSVC, \n",
    "               'SGDClassifier': SGDClassifier, 'RidgeClassifier': RidgeClassifier}.items():\n",
    "    print(name)\n",
    "    models[name]=make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=777)).fit(train,y)\n",
    "    #models[name]=make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=777, class_weight='balanced')).fit(train,y)\n",
    "yp = models['LogisticRegression'].predict(train)\n",
    "confusion_matrix(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[ 690,   36],\n",
    "       [ 140, 1134]], dtype=int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['LogisticRegression'].fit(train,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Так как целевая переменная не сбалансирована, добавим 500 негативных отзывов в обучающую выборку и сравним результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('products_sentiment_train.tsv', sep='\\t',  header=None)\n",
    "train = shuffle(train.append(train.iloc[list(train[train[1] == 0].index[:500])]), random_state=10)\n",
    "y = train[1]\n",
    "X = train[0]\n",
    "y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И снова прогоняем наши модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for name, clf in {'LogisticRegression': LogisticRegression, 'LinearSVC': LinearSVC, \n",
    "               'SGDClassifier': SGDClassifier, 'RidgeClassifier': RidgeClassifier}.items():\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=777)), X, y, cv=5).mean()\n",
    "    print(f\"{name} - {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "models={}\n",
    "for name, clf in {'LogisticRegression': LogisticRegression, 'LinearSVC': LinearSVC, \n",
    "               'SGDClassifier': SGDClassifier, 'RidgeClassifier': RidgeClassifier}.items():\n",
    "    models[name]=make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=777)).fit(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = models['LogisticRegression'].predict(X)\n",
    "confusion_matrix(y,yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = [145] #range(100, 200, 5)\n",
    "m_s = [2]#, 3, 4]\n",
    "regressor = RandomForestRegressor(random_state=0)\n",
    "grid = {'n_estimators': est, 'min_samples_split': m_s}\n",
    "gs = GridSearchCV(regressor, grid, scoring = 'neg_mean_squared_error', n_jobs = -1, verbose = 10 )\n",
    "gs.fit(scaler.fit_transform(X_train), y_train)\n",
    "y_pred = gs.predict(scaler.transform(X_test))\n",
    "t = mean_squared_error(y_test, y_pred)\n",
    "print(t, np.exp(t))\n",
    "gs.best_params_\n",
    "\n",
    "\n",
    "params_grid_lsvc = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'], \n",
    "    'classifier__max_iter': np.arange(100, 1000, 50),\n",
    "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'classifier__C': np.arange(0.1, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в этом месте я рыдаю, выкидываю все, что было раньше, и делаю все заново"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.02, max_df=0.9, ngram_range=(3,12), sublinear_tf=True, analyzer='char_wb')\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\n",
    "    'classifier__loss': ['squared_hinge'], \n",
    "    'classifier__max_iter': np.arange(100, 1000, 50),\n",
    "    'classifier__tol': [1e-5],\n",
    "    'classifier__C': np.arange(0.1, 2, 0.1),\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__class_weight': ['balanced', None],\n",
    "    'classifier__dual':[True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vectorizer', vectorizer), \n",
    "                    ('DenseTransformer', DenseTransformer()),\n",
    "                     ('pca', PCA()),\n",
    "                    ('classifier', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lesika\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1368 candidates, totalling 4104 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:   41.7s\n",
      "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  57 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=2)]: Done  81 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=2)]: Done  94 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=2)]: Done 109 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=2)]: Done 141 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=2)]: Done 158 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=2)]: Done 177 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=2)]: Done 217 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=2)]: Done 238 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=2)]: Done 261 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=2)]: Done 309 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=2)]: Done 334 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=2)]: Done 361 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=2)]: Done 388 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=2)]: Done 417 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=2)]: Done 477 tasks      | elapsed: 23.5min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=2)]: Done 541 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=2)]: Done 574 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=2)]: Done 609 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=2)]: Done 644 tasks      | elapsed: 31.3min\n",
      "[Parallel(n_jobs=2)]: Done 681 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=2)]: Done 718 tasks      | elapsed: 34.8min\n",
      "[Parallel(n_jobs=2)]: Done 757 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 38.6min\n",
      "[Parallel(n_jobs=2)]: Done 837 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=2)]: Done 878 tasks      | elapsed: 42.6min\n",
      "[Parallel(n_jobs=2)]: Done 921 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=2)]: Done 964 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=2)]: Done 1009 tasks      | elapsed: 49.0min\n",
      "[Parallel(n_jobs=2)]: Done 1054 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=2)]: Done 1101 tasks      | elapsed: 53.7min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=2)]: Done 1197 tasks      | elapsed: 58.9min\n",
      "[Parallel(n_jobs=2)]: Done 1246 tasks      | elapsed: 61.5min\n",
      "[Parallel(n_jobs=2)]: Done 1297 tasks      | elapsed: 64.1min\n",
      "[Parallel(n_jobs=2)]: Done 1348 tasks      | elapsed: 66.9min\n",
      "[Parallel(n_jobs=2)]: Done 1401 tasks      | elapsed: 69.8min\n",
      "[Parallel(n_jobs=2)]: Done 1454 tasks      | elapsed: 72.8min\n",
      "[Parallel(n_jobs=2)]: Done 1509 tasks      | elapsed: 76.1min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 79.1min\n",
      "[Parallel(n_jobs=2)]: Done 1621 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=2)]: Done 1678 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=2)]: Done 1737 tasks      | elapsed: 88.8min\n",
      "[Parallel(n_jobs=2)]: Done 1796 tasks      | elapsed: 92.3min\n",
      "[Parallel(n_jobs=2)]: Done 1857 tasks      | elapsed: 95.6min\n",
      "[Parallel(n_jobs=2)]: Done 1918 tasks      | elapsed: 99.0min\n",
      "[Parallel(n_jobs=2)]: Done 1981 tasks      | elapsed: 102.4min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 106.2min\n",
      "[Parallel(n_jobs=2)]: Done 2109 tasks      | elapsed: 109.7min\n",
      "[Parallel(n_jobs=2)]: Done 2174 tasks      | elapsed: 113.3min\n",
      "[Parallel(n_jobs=2)]: Done 2241 tasks      | elapsed: 116.7min\n",
      "[Parallel(n_jobs=2)]: Done 2308 tasks      | elapsed: 120.0min\n",
      "[Parallel(n_jobs=2)]: Done 2377 tasks      | elapsed: 123.3min\n",
      "[Parallel(n_jobs=2)]: Done 2446 tasks      | elapsed: 126.7min\n",
      "[Parallel(n_jobs=2)]: Done 2517 tasks      | elapsed: 130.2min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed: 133.7min\n",
      "[Parallel(n_jobs=2)]: Done 2661 tasks      | elapsed: 137.6min\n",
      "[Parallel(n_jobs=2)]: Done 2734 tasks      | elapsed: 141.6min\n",
      "[Parallel(n_jobs=2)]: Done 2809 tasks      | elapsed: 145.7min\n",
      "[Parallel(n_jobs=2)]: Done 2884 tasks      | elapsed: 149.6min\n",
      "[Parallel(n_jobs=2)]: Done 2961 tasks      | elapsed: 153.6min\n",
      "[Parallel(n_jobs=2)]: Done 3038 tasks      | elapsed: 157.6min\n",
      "[Parallel(n_jobs=2)]: Done 3117 tasks      | elapsed: 161.6min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 165.7min\n",
      "[Parallel(n_jobs=2)]: Done 3277 tasks      | elapsed: 169.8min\n",
      "[Parallel(n_jobs=2)]: Done 3358 tasks      | elapsed: 173.9min\n",
      "[Parallel(n_jobs=2)]: Done 3441 tasks      | elapsed: 178.1min\n",
      "[Parallel(n_jobs=2)]: Done 3524 tasks      | elapsed: 182.2min\n",
      "[Parallel(n_jobs=2)]: Done 3609 tasks      | elapsed: 186.5min\n",
      "[Parallel(n_jobs=2)]: Done 3694 tasks      | elapsed: 190.7min\n",
      "[Parallel(n_jobs=2)]: Done 3781 tasks      | elapsed: 195.1min\n",
      "[Parallel(n_jobs=2)]: Done 3868 tasks      | elapsed: 199.4min\n",
      "[Parallel(n_jobs=2)]: Done 3957 tasks      | elapsed: 203.8min\n",
      "[Parallel(n_jobs=2)]: Done 4046 tasks      | elapsed: 208.2min\n",
      "[Parallel(n_jobs=2)]: Done 4104 out of 4104 | elapsed: 211.1min finished\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(pipeline, grid, scoring='accuracy', n_jobs = 2, verbose = 10, error_score = 0.0)\n",
    "gs.fit(train, y)\n",
    "y_pred = gs.predict(train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8545\n",
      "0.7745\n",
      "{'classifier__C': 0.2, 'classifier__class_weight': None, 'classifier__dual': True, 'classifier__loss': 'squared_hinge', 'classifier__max_iter': 100, 'classifier__penalty': 'l2', 'classifier__tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y, y_pred))\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8855\n",
    "0.983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну и постим все это на каггл. \n",
    "y_kaggle = gs.predict(test)\n",
    "t = pd.DataFrame(y_kaggle).reset_index()\n",
    "t.columns = ['Id', 'y']\n",
    "t.to_csv('kaggle_6.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
